<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents">
  <meta property="og:title" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents" />
  <meta property="og:description" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents" />
  <meta property="og:url" content="https://language-guided-world-model.github.io" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/teaser.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents">
  <meta name="twitter:description" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="ai, world model, language">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Language-Guided World Models: Enhancing Human Control over Artificial Agents</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Language-Guided World Models: Enhancing Human Control over
              Artificial Agents</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://alexzhang13.github.io" target="_blank">Alex Zhang</a><sup>*</sup><sup>&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://machineslearner.com" target="_blank">Khanh Nguyen</a><sup>*</sup><sup>&Dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://jens321.github.io" target="_blank">Jens Tuyls</a><sup>&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/albertkuilin/" target="_blank">Albert Lin</a><sup>&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://www.cs.princeton.edu/~karthikn/" target="_blank">Karthik Narasimhan</a><sup>&dagger;</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Princeton University<sup>&dagger;</sup> & UC Berkeley<sup>&Dagger;</sup></span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->

                <!-- Supplementary PDF link -->
                <!-- <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body has-text-centered">
        <!-- Your video here -->
        <img src="static/images/teaser.gif" alt="Teaser figure." width="900">
        <!-- <source src="static/videos/banner_video.mp4" type="video/mp4"> -->
        <h2 class="subtitle has-text-centered">
          <b> tldr; We build world models that can be modulated using natural language called Language-guided World
            Models (LWMs), allowing model-based agents to be controlled through a natural language interface. </b>
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified">
            <p style="font-weight: normal">
              Putting artificial agents under human control is vital in order to sustainably
              leverage their powerful capabilities. Installing probabilistic world models into
              artificial agents opens an unprecedented channel for humans to direct the behavior
              of these agents. Besides allowing for explicit behavior regulation through policy
              alteration, model-based agents enable implicit behavior regulation through world
              model adaptation. Nevertheless, current world models lack a natural interface
              for humans to easily adapt them.
              <br><br>
              To address this shortcoming, we introduce
              Language-Guided World Models (LWMs), which can be modulated with natural
              language. To facilitate the development of these models, we design a challenging
              benchmark based on the game of MESSENGER (<a href="https://arxiv.org/abs/2101.07393">Hanjie et al.,
                2021</a>), requiring
              compositional generalization to new language descriptions and environment
              dynamics. We show that the current state-of-the-art Transformer architecture
              performs poorly on this benchmark, and develop a more robust architecture. To
              showcase the practicality of our approach, we illustrate the effectiveness of LWMs
              in facilitating safe human-agent collaboration in a simulated setting.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- How it Works -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Our Approach</h2>
          <div class="content has-text-justified">
            <p style="font-weight: normal">
                Learning LWMs poses a challenging problem involving the retrieval and incorporation of information across different
                modalities.
                
                Our model is an encoder-decoder Transformer which encodes a manual and decodes a trajectory.
                We transform the trajectory into a long sequence of tokens and train the model as a sequence generator.
                <br> <br>
                <img src="static/images/teaser.png" alt="Teaser figure." width="1500">

                (a) These models enable agents to compose intuitive plans and invite a human supervisor to validate and revise those plans.
                The supervisor is offered various strategies for revising a plan: they can either propose a new plan to directly update
                the agent policy, or provide verbal descriptions of the environment to modify the world model, which indirectly changes
                the plan.
                <br> <br>
                (b) We design an effective architecture for language-guided world models that demonstrates strong compositional
                generalizability. Our approach converts a trajectory into a long sequence of tokens and trains a Transformer to
                auto-regressively generate these tokens. It implements a specialized attention mechanism inspired by
                <a href="https://arxiv.org/abs/2101.07393">Hanjie et al., 2021</a> to incorporate textual information into the observation tokens.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- End youtube video -->

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths has-text-centered">
            <!-- Paper video. -->
            <h2 class="title is-3">Environment with Text Manuals</h2>
            <div class="content is-centered has-text-justified">
              <p style="font-weight: normal">
                We evaluate on MESSENGER (<a href="https://arxiv.org/abs/2101.07393">Hanjie et al., 2021</a>) to evaluate <b>compositional generalization</b>.
                A player interacts with entities having one of three <i>roles</i>: message, goal, or enemy.
                The objective of the player is to acquire the message and deliver it to the goal while avoiding the enemy.
                In addition to the role, each entity is assigned an <i>identity</i> among twelve possibilities (mage, airplane, orb,
                etc.) and a <i>movement pattern</i> (chasing the agent, fleeing from the agent, immobile). Each game features an associated game manual, each of which describes the entity dynamics in natural language.
              </p>
              <br>
              <div class="has-text-centered">
                <img src="static/images/messenger.png" alt="Teaser figure." width="400">
              </div>
              <p style="font-weight: normal">
              We create three levels of compositional generalization to evaluate our agents on.
              </p>
              <ul style="font-weight: normal">
                <li> <b>NewCombo (easy).</b> Each game features a combination of three identities that were never seen together in a
                training game.
                However, the attributes (role and movement pattern) of each identity are the same as during training.</li>
                
                <li><b>NewAttr (medium).</b> The three identities were seen together in a training game, but each identity is
                assigned at least a new attribute (role, or movement pattern, or both).</li>
                
                <li><b>NewAll (hard).</b> This setting combines the difficulties of the previous two. The identity triplet is novel,
                and each identity is assigned at least a new attribute.</li>
              </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths has-text-centered">
            <!-- Paper video. -->
            <h2 class="title is-3">Language-guided World Model (LWM) Learning</h2>
            <div class="content is-centered has-text-justified">
              <p style="font-weight: normal">
               </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths has-text-centered">
            <!-- Paper video. -->
            <h2 class="title is-3">Downstream LWM Policy Learning</h2>
            <div class="content is-centered has-text-justified">
              <p style="font-weight: normal">
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre>
<code>@article{zhang2024languageguided
  title={Language-Guided World Models: Enhancing Human Control Over Artificial Agents},
  author={Zhang, Alex and Nguyen, Khanh and Tuyls, Jens and Lin, Albert and Narasimhan, Karthik},
  year={2024},
  eprint={},
  archivePrefix={arXiv},
}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
