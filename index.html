<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents">
  <meta property="og:title" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents" />
  <meta property="og:description" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents" />
  <meta property="og:url" content="https://language-guided-world-model.github.io" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/teaser.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents">
  <meta name="twitter:description" content="Language-Guided World Models: Enhancing Human Control over Artificial Agents">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="ai, world model, language">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Language-Guided World Models: Enhancing Human Control over Artificial Agents</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Language-Guided World Models <img src="static/images/icon.png" alt="language-guided world model" style="width:4rem; height:4rem;">: Shaping Artificial Minds through Words</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://alexzhang13.github.io" target="_blank">Alex Zhang</a><sup>*</sup><sup>&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://machineslearner.com" target="_blank">Khanh Nguyen</a><sup>*</sup><sup>&Dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://jens321.github.io" target="_blank">Jens Tuyls</a><sup>&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/albertkuilin/" target="_blank">Albert Lin</a><sup>&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://www.cs.princeton.edu/~karthikn/" target="_blank">Karthik Narasimhan</a><sup>&dagger;</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Princeton University<sup>&dagger;</sup> & UC Berkeley<sup>&Dagger;</sup></span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->

                <!-- Supplementary PDF link -->
                <!-- <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser video-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body has-text-centered">
        <!-- Your video here -->
        <img src="static/images/application.png" alt="teaser" style="max-width: 50%">
        <!-- <source src="static/videos/banner_video.mp4" type="video/mp4"> -->
        <h2 class="subtitle">
          <b> We build world models that can be adapted through natural language. These models can be incorporated into artificial agents, allowing humans to control them more effectively.</b>
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video --> 



  <!-- Paper abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified">
            <p style="font-weight: normal">
              Putting artificial agents under human control is vital in order to leverage their powerful capabilities. Installing probabilistic world models into artificial agents opens an unprecedented channel for humans to control these agents. In addition to being able to regulate the behavior of agents through direct policy update, humans can modify their world models to effectively influence their decisions. Nevertheless, current world models are difficult for humans to adapt because they lack a natural communication interface. 
<br/><br/>
We introduce <strong>Language-Guided World Models</strong> (LWMs), which can be modulated via natural language. To facilitate the development of LWMs, we design a challenging benchmark based on the game of MESSENGER  (<a href="https://arxiv.org/abs/2101.07393">Hanjie et al.,2021</a>), requiring compositional generalization to new language descriptions and environment dynamics. We show that the current state-of-the-art Transformer architecture performs poorly on this benchmark, and develop a more robust architecture. To showcase the practicality of LWMs, we simulate a scenario where these models facilitate safe and transparent human-agent collaboration. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- How it Works -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Our Approach</h2>
          <div class="content has-text-justified">
            <p style="font-weight: normal">
                Learning LWMs poses a challenging problem involving the retrieval and incorporation of information expressed in different modalities. Our model is an encoder-decoder Transformer which encodes a manual and decodes a trajectory. We transform the trajectory into a long sequence of tokens and train the model as a sequence generator. We implement a specialized attention mechanism inspired by EMMA (<a href="https://arxiv.org/abs/2101.07393">Hanjie et al., 2021</a>) to incorporate textual information into the observation tokens.
                <br> <br>
                <img src="static/images/model.png" alt="model" style="max-width: 100%">
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- End youtube video -->

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths has-text-centered">
            <!-- Paper video. -->
            <h2 class="title is-3">Benchmarking Compositional Generalizability</h2>
            <div class="content is-centered has-text-justified">
              <p style="font-weight: normal">
              Our goal is to build world models that can generalize to <i>compositionally</i> novel texts and environment dynamics. We construct a challenging benchmark based on the MESSENGER environment to evaluate this capability of world models. The benchmark tests a model on various levels of compositional generalization.
              </p>
              <br>
              <div class="has-text-centered">
                <img src="static/images/messenger.png" alt="messenger" width="400">
              </div>
             </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths has-text-centered">
            <!-- Paper video. -->
            <h2 class="title is-3">Results</h2>
            <div class="content is-centered has-text-justified">
              <div class="has-text-centered">
                <img src="static/images/fig4_u.png" alt="Teaser figure." width="700">
              </div>
              <p style="font-weight: normal">
              We demonstrate the effectiveness of our proposed model through both intrinsic and extrinsic evaluations. The model outperforms the standard encoder-decoder Transformer and approaches the performance of an oracle with a perfect semantic-parsing capability. 
              </p>
              <div class="has-text-centered">
                <img src="static/images/result_intrinsic.png" alt="result intrinsic" style="max-width: 49%">
                <img src="static/images/result_extrinsic.png" alt="result extrinsic" style="max-width: 49%">
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre>
<code>@article{zhang2024languageguided
  title={Language-Guided World Models: Enhancing Human Control Over Artificial Agents},
  author={Zhang, Alex and Nguyen, Khanh and Tuyls, Jens and Lin, Albert and Narasimhan, Karthik},
  year={2024},
  journal={arXiv},
}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
